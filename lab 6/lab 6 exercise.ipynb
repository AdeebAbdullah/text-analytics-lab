{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e037b83d-7701-4683-84b6-db77f45d34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mdade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mdade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mdade\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For model training later\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaddfbcf-8860-445b-b9e1-37d00b6bc924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Review', 'lowercased', 'urls_removed', 'html_removed',\n",
      "       'emojis_removed', 'slangs_replaced', 'contractions_replaced',\n",
      "       'punctuations_removed', 'numbers_removed', 'spelling_corrected',\n",
      "       'stopwords_removed', 'stemmed_words', 'lemmatized', 'tokenized',\n",
      "       'Label'],\n",
      "      dtype='object')\n",
      "                                              Review  \\\n",
      "0  The product arrived on time. Packaging was gre...   \n",
      "1           THIS PRODUCT IS JUST AMAZING! I LOVE IT.   \n",
      "2  I bought this phone for $799, and it has a 120...   \n",
      "3  Wow!!! This product is awesome... but a bit ex...   \n",
      "4                The laptop works perfectly fine.      \n",
      "\n",
      "                                          lowercased  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                        urls_removed  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                        html_removed  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                      emojis_removed  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                     slangs_replaced  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                               contractions_replaced  \\\n",
      "0  the product arrived on time. packaging was gre...   \n",
      "1           this product is just amazing! i love it.   \n",
      "2  i bought this phone for $799, and it has a 120...   \n",
      "3  wow!!! this product is awesome... but a bit ex...   \n",
      "4                the laptop works perfectly fine.      \n",
      "\n",
      "                                punctuations_removed  \\\n",
      "0  the product arrived on time packaging was grea...   \n",
      "1             this product is just amazing i love it   \n",
      "2  i bought this phone for 799 and it has a 120hz...   \n",
      "3    wow this product is awesome but a bit expensive   \n",
      "4                 the laptop works perfectly fine      \n",
      "\n",
      "                                     numbers_removed  \\\n",
      "0  the product arrived on time packaging was grea...   \n",
      "1             this product is just amazing i love it   \n",
      "2  i bought this phone for  and it has a hz displ...   \n",
      "3    wow this product is awesome but a bit expensive   \n",
      "4                 the laptop works perfectly fine      \n",
      "\n",
      "                                  spelling_corrected  \\\n",
      "0  the product arrived on time packaging was grea...   \n",
      "1             this product is just amazing i love it   \n",
      "2  i bought this phone for  and it has a hz displ...   \n",
      "3    wow this product is awesome but a bit expensive   \n",
      "4                 the laptop works perfectly fine      \n",
      "\n",
      "                                   stopwords_removed  \\\n",
      "0  product arrived time packaging great quality a...   \n",
      "1                               product amazing love   \n",
      "2              bought phone hz display totally worth   \n",
      "3                  wow product awesome bit expensive   \n",
      "4                        laptop works perfectly fine   \n",
      "\n",
      "                                  stemmed_words  \\\n",
      "0  product arriv time packag great qualiti amaz   \n",
      "1                             product amaz love   \n",
      "2           bought phone hz display total worth   \n",
      "3                 wow product awesom bit expens   \n",
      "4                    laptop work perfectli fine   \n",
      "\n",
      "                                          lemmatized  \\\n",
      "0  product arrive time packaging great quality am...   \n",
      "1                                 product amaze love   \n",
      "2                 buy phone hz display totally worth   \n",
      "3                  wow product awesome bit expensive   \n",
      "4                         laptop work perfectly fine   \n",
      "\n",
      "                                           tokenized  Label  \n",
      "0  ['product', 'arrive', 'time', 'packaging', 'gr...      1  \n",
      "1                       ['product', 'amaze', 'love']      1  \n",
      "2  ['buy', 'phone', 'hz', 'display', 'totally', '...      1  \n",
      "3  ['wow', 'product', 'awesome', 'bit', 'expensive']      0  \n",
      "4            ['laptop', 'work', 'perfectly', 'fine']      1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('Processed_Reviews.csv')  \n",
    "\n",
    "# Check column names and first few rows\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da395c37-6658-486a-b19d-f6a7a6324f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0  The product arrived on time. Packaging was gre...   \n",
      "1           THIS PRODUCT IS JUST AMAZING! I LOVE IT.   \n",
      "2  I bought this phone for $799, and it has a 120...   \n",
      "3  Wow!!! This product is awesome... but a bit ex...   \n",
      "4                The laptop works perfectly fine.      \n",
      "\n",
      "                                          lemmatized  \n",
      "0  product arrived time packaging great quality a...  \n",
      "1                               product amazing love  \n",
      "2                 bought phone display totally worth  \n",
      "3                  wow product awesome bit expensive  \n",
      "4                         laptop work perfectly fine  \n"
     ]
    }
   ],
   "source": [
    "# Set up lemmatizer and stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define clean+lemmatize function\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    tokens = nltk.word_tokenize(text.lower())  # lowercase + tokenize\n",
    "    words = [word for word in tokens if word.isalpha()]  # remove punctuation/numbers\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]  # remove stopwords & lemmatize\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply it\n",
    "df['lemmatized'] = df['Review'].apply(lemmatize_text)\n",
    "\n",
    "# Check if it worked\n",
    "print(df[['Review', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af43d2ae-9662-4e88-86fa-40b042749b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, rows left: 13\n"
     ]
    }
   ],
   "source": [
    "# Drop empty rows\n",
    "df['lemmatized'] = df['lemmatized'].astype(str).str.strip()\n",
    "df = df[df['lemmatized'].str.len() > 0]\n",
    "\n",
    "print(\"After cleaning, rows left:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "796b379e-6623-4f99-b75d-f794387f2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform\n",
    "X = tfidf_vect.fit_transform(df['lemmatized'])\n",
    "\n",
    "# Define labels (target)\n",
    "y = df['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de0bcb28-ecbb-4283-aa6e-059cbac13290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (TF-IDF Features): (13, 53)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Apply TF-IDF vectorization to lemmatized reviews\n",
    "X = tfidf_vect.fit_transform(df['lemmatized'])\n",
    "\n",
    "# Check the shape of the resulting matrix\n",
    "print(f\"Shape of X (TF-IDF Features): {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f2ce793-c02e-4de6-9681-3ae42e4ea965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 10, Test set size: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the target variable 'y'\n",
    "y = df['Label']\n",
    "\n",
    "# Train-test split (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the split shapes\n",
    "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf510d53-c72b-49b0-a139-4269fcbfefc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "train_score = model.score(X_train, y_train)\n",
    "print(f\"Training accuracy: {train_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d53f1d09-f8aa-4634-ba54-e7bb8beeb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1eb02-aa96-4b9e-9fd2-0bc63f599768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
